{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9cbcdaa4-e96a-47f8-9675-4b885b8a4e46",
   "metadata": {},
   "source": [
    "<h4>Mironov Mikhail. Master Thesis. Main research notebook</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2025-05-26T12:51:54.157573Z"
    },
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "from datetime import date, timedelta\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from core.currency import Currency\n",
    "from core.exchange import Exchange\n",
    "from core.time_utils import Bounds\n",
    "from core.utils import configure_logging\n",
    "from ml_base.features import FeatureFilter, get_importance_file_path\n",
    "from ml_base.metrics import log_lgbm_iteration_to_stdout\n",
    "from typing import *\n",
    "\n",
    "warnings.simplefilter(\"ignore\")\n",
    "\n",
    "configure_logging()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2e57840-8b90-4e15-8e87-7c2a9d7b0c42",
   "metadata": {},
   "source": [
    "<h4>Display how raw data looks</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5653ced-989c-49ba-b82c-c3e80ddd417c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from core.paths import BINANCE_SPOT_HIVE_TRADES\n",
    "from core.time_utils import Bounds\n",
    "from datetime import date\n",
    "\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "\n",
    "\n",
    "bounds: Bounds = Bounds.for_day(date(2025, 5, 1))\n",
    "\n",
    "df = (\n",
    "    pl.scan_parquet(BINANCE_SPOT_HIVE_TRADES, hive_partitioning=True)\n",
    "    .filter(\n",
    "        (pl.col(\"symbol\") == \"ADA-USDT\") &\n",
    "        (pl.col(\"date\") == bounds.day0)\n",
    "    )\n",
    "    .head(5)\n",
    "    .collect()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e08a396a-8f34-485f-94e6-722dc29bc05f",
   "metadata": {},
   "source": [
    "<h4>Load most significant features</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1b79a50f-7624-4edf-996d-e6f2733cde95",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-27 13:50:53,255 | INFO | root | Loading feature importance file D:\\microstructure_ranker\\src\\models\\prediction\\artifacts\\feature_importances\\BINANCE_SPOT\\BINANCE_SPOT-importances-3S@20250525.csv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['ETH-asset_return-2S@BINANCE_SPOT',\n",
       " 'ETH-asset_return-1S@BINANCE_SPOT',\n",
       " 'SELF-flow_imbalance-2S@BINANCE_USDM',\n",
       " 'currency_index',\n",
       " 'ETH-asset_return-500MS@BINANCE_SPOT',\n",
       " 'SELF-flow_imbalance-5S@BINANCE_USDM',\n",
       " 'SELF-exchange_diff-BINANCE_SPOT-BINANCE_USDM-2S',\n",
       " 'ETH-asset_return-5S@BINANCE_SPOT',\n",
       " 'SELF-flow_imbalance-1S@BINANCE_USDM',\n",
       " 'SELF-exchange_diff-BINANCE_SPOT-BINANCE_USDM-500MS']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load features that are the most impactful\n",
    "feature_filter: FeatureFilter = FeatureFilter.from_importance(\n",
    "    get_importance_file_path(\n",
    "        day=date(2025, 5, 25),\n",
    "        target_exchange=Exchange.BINANCE_SPOT,\n",
    "        forecast_step=timedelta(seconds=3)\n",
    "    ),\n",
    "    use_first=25\n",
    ")\n",
    "\n",
    "feature_filter.allowed_features[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5df65c5b-48f2-46c0-bec7-5ef17ccb0f38",
   "metadata": {},
   "source": [
    "<h4>Define bounds for TRAIN and TEST samples</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a094b6b9-243d-4660-a8f2-90d1b6999e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_bounds: Bounds = Bounds.for_days(\n",
    "    date(2025, 4, 1), date(2025, 5, 5)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea489d17-9237-480f-89fe-155c6e1cc7db",
   "metadata": {},
   "source": [
    "<h4>Build model manually</h4>\n",
    "\n",
    "\n",
    "<p>Using BuildDataset read all features and split them into TRAIN and VALIDATION samples</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a666749b-4646-4ebc-8442-6f6d80e4b5a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from core.currency import get_target_currencies\n",
    "from models.prediction.build_sample import BuildDataset\n",
    "from ml_base.sample import SampleParams, Sample, MLDataset\n",
    "from ml_base.enums import DatasetType\n",
    "\n",
    "sample: Sample = (\n",
    "    BuildDataset(\n",
    "        target_exchange=Exchange.OKX_SPOT,\n",
    "        feature_filter=feature_filter,\n",
    "        target_currencies=get_target_currencies(),\n",
    "        forecast_step=timedelta(seconds=5),\n",
    "    )\n",
    "    .create_sample(\n",
    "        bounds=train_bounds,\n",
    "        sample_params=SampleParams(train_share=.8, validation_share=.2),\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e981ed91-586a-42d9-abef-6ff21f493821",
   "metadata": {},
   "source": [
    "<h4>Visualize data</h4>\n",
    "\n",
    "<p>We can get DataFrame from MLDataset</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29eb1708-1ac8-41a3-8be3-51d595954c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = sample.get_data(ds_type=DatasetType.TRAIN)\n",
    "df_val = sample.get_data(ds_type=DatasetType.VALIDATION)\n",
    "\n",
    "df_train.shape, df_val.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0630dba4-600e-4ec4-89ad-b63015fc201e",
   "metadata": {},
   "source": [
    "<p>In MLDataset.eval_fields we have stored asset_hold_time. Now we will check what was the actual time between trades used to compute returns for different time horizons</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "620eb10c-e1c6-446f-9ad7-229f9bfcdc52",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_eval: pd.DataFrame = sample.get_eval_data(ds_type=DatasetType.TRAIN)\n",
    "val_eval: pd.DataFrame = sample.get_eval_data(ds_type=DatasetType.VALIDATION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ecac339-4735-4d62-b2e1-6841935e1347",
   "metadata": {},
   "outputs": [],
   "source": [
    "currencies: List[Currency] = [Currency.BTC, Currency.ETH, Currency.HBAR]\n",
    "vals: List[pd.Series] = []\n",
    "\n",
    "for currency in currencies:\n",
    "    mask = df_train[\"currency_index\"] == currency.value\n",
    "    vals.append(train_eval[mask].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d514c896-c308-455d-8334-76f988b1d1fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get hold_time for different windows for less traded currency like HBAR\n",
    "df_liquidity = pd.DataFrame(vals).T\n",
    "df_liquidity.columns = [currency.name for currency in currencies]\n",
    "\n",
    "\n",
    "df_liquidity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e231fbab-3034-47cc-a0a7-f2f969a607cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.sample(int(5 * 1e6), replace=False).describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cedf58f1-1d5e-4cb8-b5f3-799cda06e1e8",
   "metadata": {},
   "source": [
    "<h4>Train the model with early stopping on the validation sample</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fda7f3e9-4c2d-4cd5-bace-6379e71a0251",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now train the model using LightGBM\n",
    "from lightgbm import Booster, record_evaluation\n",
    "from typing import *\n",
    "import lightgbm as lgb\n",
    "import os\n",
    "\n",
    "_BASE_PARAMS: Dict[str, Any] = {\n",
    "    \"objective\": \"mse\",\n",
    "    \"max_depth\": 10,\n",
    "    \"learning_rate\": 0.05,\n",
    "    \"n_estimators\": 120,\n",
    "    \"subsample\": 0.7,\n",
    "    \"num_threads\": os.cpu_count() - 1,\n",
    "    \"verbose\": -1\n",
    "}\n",
    "\n",
    "evals_result = {}\n",
    "\n",
    "train: lgb.Dataset = sample.get_lgb_dataset(ds_type=DatasetType.TRAIN)\n",
    "validation: lgb.Dataset = sample.get_lgb_dataset(ds_type=DatasetType.VALIDATION)\n",
    "\n",
    "booster: Booster = lgb.train(\n",
    "    params=_BASE_PARAMS,\n",
    "    train_set=train,\n",
    "    valid_sets=[train, validation],\n",
    "    valid_names=[\"train\", \"validation\"],\n",
    "    callbacks=[\n",
    "        record_evaluation(evals_result),\n",
    "        lgb.early_stopping(stopping_rounds=50, verbose=False),\n",
    "        log_lgbm_iteration_to_stdout\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d68f89be-0e10-48f8-bdea-bbdb8cf8a46a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax1 = plt.subplots()\n",
    "\n",
    "ax1.set_xlabel('Iteration')\n",
    "ax1.plot(evals_result[\"train\"][\"l2\"], label='Train L2', color=\"red\")\n",
    "\n",
    "# create a second y-axis sharing the same x\n",
    "ax2 = ax1.twinx()\n",
    "ax2.plot(evals_result[\"validation\"][\"l2\"], label='Validation L2', color=\"blue\")\n",
    "\n",
    "fig.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44111a35-88fa-49be-b44a-83e49142a993",
   "metadata": {},
   "source": [
    "<h4>Evaluate the model</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e8bf15d-5700-4ac5-af05-46b843cffc69",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_ds: MLDataset = sample.get_dataset(ds_type=DatasetType.VALIDATION)\n",
    "y_pred: np.ndarray = booster.predict(val_ds.data, num_iteration=booster.best_iteration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c790c6fa-a052-4e48-b9bd-898a8ba9c33f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score, classification_report, accuracy_score\n",
    "\n",
    "r2_score(y_pred=y_pred, y_true=val_ds.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "140a091b-9ece-48b6-928d-325d102a5d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_binary: np.ndarray = (y_pred > 0).astype(int)\n",
    "y_true_binary: np.ndarray = (val_ds.label > 0).astype(int)\n",
    "\n",
    "print(\n",
    "    classification_report(y_pred=y_pred_binary, y_true=y_true_binary)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08c1db0f-01ca-4454-b326-5b48e63fad06",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y_pred=y_pred_binary, y_true=y_true_binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6882534d-049c-4605-9d4e-1a9ac0593152",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display r2 by currency\n",
    "from ml_base.metrics import compute_metrics\n",
    "\n",
    "\n",
    "compute_metrics(\n",
    "    booster=booster, dataset=val_ds, target_currencies=get_target_currencies()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2d5d4f2-654e-4a11-8214-ebc4fe645402",
   "metadata": {},
   "source": [
    "<h4>Load feature importances and statistics</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51e502f3-eaa5-4d4b-b21d-c094d2b7c96f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.prediction.horizon import get_statitics_path, HORIZONS\n",
    "from core.time_utils import get_seconds_slug\n",
    "from ml_base.features import get_importance_file_path\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "target_exchange: Exchange = Exchange.BINANCE_SPOT\n",
    "ref_day: date = date(2025, 5, 25)\n",
    "\n",
    "\n",
    "def load_stats(target_exchange: Exchange, ref_day: date) -> pd.DataFrame:\n",
    "    dfs: List[pd.DataFrame] = []\n",
    "    \n",
    "    for forecast_step in HORIZONS:\n",
    "        path: Path = get_statitics_path(\n",
    "            target_exchange=target_exchange, forecast_step=forecast_step, day=ref_day\n",
    "        )\n",
    "    \n",
    "        df_stats: pd.DataFrame = pd.read_csv(path)\n",
    "        df_stats[\"forecast_seconds\"] = get_seconds_slug(td=forecast_step)\n",
    "        dfs.append(df_stats)\n",
    "    return pd.concat(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6430e26b-0d61-4237-9614-b239c589bb1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "binance_spot: pd.DataFrame = load_stats(target_exchange=Exchange.BINANCE_SPOT, ref_day=ref_day)\n",
    "binance_usdm: pd.DataFrame = load_stats(target_exchange=Exchange.BINANCE_USDM, ref_day=ref_day)\n",
    "okx_spot: pd.DataFrame = load_stats(target_exchange=Exchange.OKX_SPOT, ref_day=ref_day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd2965c5-692f-423a-a466-6d7b3d9456ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "binance_spot = binance_spot.set_index(['currency', 'forecast_seconds'])\n",
    "binance_usdm = binance_usdm.set_index(['currency', 'forecast_seconds'])\n",
    "okx_spot = okx_spot.set_index(['currency', 'forecast_seconds'])\n",
    "\n",
    "# 2. give each block of columns a top–level name\n",
    "binance_spot.columns = pd.MultiIndex.from_product([['BINANCE_SPOT'], binance_spot.columns])\n",
    "binance_usdm.columns = pd.MultiIndex.from_product([['BINANCE_USDM'], binance_usdm.columns])\n",
    "okx_spot.columns = pd.MultiIndex.from_product([['OKX_SPOT'], okx_spot.columns])\n",
    "\n",
    "# 3. concatenate them side by side\n",
    "df_combined = pd.concat([binance_spot, binance_usdm, okx_spot], axis=1).reset_index()\n",
    "df_combined = df_combined.set_index(['currency','forecast_seconds'])\n",
    "df_combined = df_combined.sort_index(level=['currency','forecast_seconds'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a359aa78-5967-4139-853c-3aa82a3aae35",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d6be169-62b8-44d8-bdbc-ec7d11ab509b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined.index[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8ce88f4-a950-4dbc-b225-e04c54df9fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined = df_combined.round(3)\n",
    "\n",
    "# 3. Export to LaTeX, making sure float_format keeps three decimals\n",
    "latex = df_combined.to_latex(\n",
    "    index=True,\n",
    "    multicolumn=True,\n",
    "    multirow=True,\n",
    "    float_format=\"%.3f\",\n",
    "    column_format='ll' + 'rrrr'*2\n",
    ")\n",
    "\n",
    "print(latex.replace(\"_\", \"-\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c791225-3259-4bad-bf82-abe01bc07e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_exchange: Exchange = Exchange.OKX_SPOT\n",
    "\n",
    "df_stats: pd.DataFrame = load_stats(target_exchange=target_exchange, ref_day=ref_day)\n",
    "ax = plt.figure(figsize=(9, 5)).add_subplot()\n",
    "\n",
    "for currency in df_stats[\"currency\"].unique():\n",
    "    df_stats[df_stats[\"currency\"] == currency].plot(\n",
    "        x=\"forecast_seconds\", y=\"R2\", \n",
    "        ax=ax, \n",
    "        label=currency,\n",
    "    )\n",
    "\n",
    "\n",
    "plt.ylabel(\"R2\")\n",
    "plt.title(f\"R2 by currency at {target_exchange.name} against forecast horizon\")\n",
    "ax.legend(loc='center left', bbox_to_anchor=(1.0, 0.5))\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"r2_by_currency@{target_exchange.name.lower()}.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a579d6e-4cb5-4c22-9fc3-3b7c5a1a92f9",
   "metadata": {},
   "source": [
    "<h4>Study feature importances</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcaf5564-949c-4be0-90a5-6693fb8d406c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_importances(target_exchange: Exchange, ref_day: date) -> pd.DataFrame:\n",
    "    dfs: List[pd.DataFrame] = []\n",
    "\n",
    "    for forecast_step in HORIZONS:\n",
    "        path: Path = get_importance_file_path(\n",
    "            target_exchange=target_exchange, forecast_step=forecast_step, day=ref_day\n",
    "        )\n",
    "    \n",
    "        df_importances: pd.DataFrame = pd.read_csv(path)\n",
    "        df_importances[\"forecast_seconds\"] = forecast_step.total_seconds()\n",
    "        dfs.append(df_importances)\n",
    "    \n",
    "    df_importances: pd.DataFrame = pd.concat(dfs)\n",
    "    return df_importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27398802-1aee-4ce5-9126-a77a33dafdc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_spot = load_importances(target_exchange=Exchange.BINANCE_SPOT, ref_day=ref_day)\n",
    "df_usdm = load_importances(target_exchange=Exchange.BINANCE_USDM, ref_day=ref_day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "898e4188-3a6f-4bde-bd95-5d6f3119eae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# ─── 1. Keep only the 3-second horizon ─────────────────────────────────────────\n",
    "df_spot_3s = df_spot[df_spot['forecast_seconds'] == 3]\n",
    "df_usdm_3s = df_usdm[df_usdm['forecast_seconds'] == 3]\n",
    "\n",
    "# ─── 2. Sort by descending importance and take the top 20 ─────────────────────\n",
    "top_spot_3s = df_spot_3s.sort_values('importance', ascending=False).head(20)\n",
    "top_usdm_3s = df_usdm_3s.sort_values('importance', ascending=False).head(20)\n",
    "\n",
    "# ─── 3. Build an empty result DataFrame with ranks 1–20 and two columns ───────\n",
    "ranks   = range(1, 21)\n",
    "columns = ['BINANCE_SPOT', 'BINANCE_USDM']\n",
    "result_3s = pd.DataFrame(index=ranks, columns=columns)\n",
    "\n",
    "# ─── 4. Populate with feature names ────────────────────────────────────────────\n",
    "result_3s['BINANCE_SPOT'] = top_spot_3s['feature'].values\n",
    "result_3s['BINANCE_USDM'] = top_usdm_3s['feature'].values\n",
    "\n",
    "# ─── 5. (Optional) Fill any missing slots with empty strings ──────────────────\n",
    "result_3s = result_3s.fillna('')\n",
    "\n",
    "# ─── Now `result_3s` is a 20×2 DataFrame:\n",
    "#      index = rank 1…20\n",
    "#      columns = BINANCE_SPOT, BINANCE_USDM\n",
    "#      values = feature names sorted by importance for the 3s horizon\n",
    "print(result_3s.to_latex().replace(\"_\", \"-\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9794aed2-d1d4-481a-8be9-abf2d7ada1a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f303199b-71f8-4d19-b3a4-fdd6fa8b05d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wide = (\n",
    "    df_importances\n",
    "    .pivot(index=\"feature\", columns=\"forecast_seconds\", values=\"importance\")\n",
    "    .fillna(0)\n",
    ")\n",
    "\n",
    "# 2) Normalize within each horizon (optional, so columns sum to 1)\n",
    "df_norm = df_wide.div(df_wide.sum(axis=0), axis=1)\n",
    "\n",
    "# 3) Sort features by *mean* importance across all horizons\n",
    "feature_order = df_norm.mean(axis=1).sort_values(ascending=False).index\n",
    "df_norm = df_norm.reindex(feature_order)\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.heatmap(\n",
    "    df_norm.iloc[:20],\n",
    "    cmap=\"viridis\",\n",
    "    cbar_kws={\"label\": \"Relative importance\"},\n",
    "    linewidths=0.5,\n",
    ")\n",
    "plt.xlabel(\"Forecast horizon\")\n",
    "plt.ylabel(\"Feature\")\n",
    "plt.title(f\"Top {10} features by normalized importance\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"feature_importances_against_all_horizons@binance_spot.png\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
